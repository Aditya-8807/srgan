{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7s9Hk3lVhbyy",
        "outputId": "8abc7c69-06ec-4814-e3d5-bd42f607a931"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Project directories created successfully!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Create the main project structure\n",
        "os.makedirs(\"src/models\", exist_ok=True)\n",
        "os.makedirs(\"src/utils\", exist_ok=True)\n",
        "os.makedirs(\"checkpoints\", exist_ok=True)\n",
        "os.makedirs(\"results/generated_images\", exist_ok=True)\n",
        "os.makedirs(\"logs\", exist_ok=True)\n",
        "os.makedirs(\"data\", exist_ok=True)\n",
        "\n",
        "\n",
        "print(\"✅ Project directories created successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/config.py\n",
        "import torch\n",
        "\n",
        "class Config:\n",
        "    # --- Data Paths ---\n",
        "    DATA_ROOT = './data/DIV2K/'\n",
        "    TRAIN_HR_DIR = DATA_ROOT + 'DIV2K_train_HR/'\n",
        "    TRAIN_LR_DIR = DATA_ROOT + 'DIV2K_train_LR_bicubic/X4/'\n",
        "\n",
        "    # --- Model & Training Parameters ---\n",
        "    SCALE_FACTOR = 4\n",
        "    IN_CHANNELS = 3\n",
        "    NUM_RRDB_BLOCKS = 23\n",
        "    BATCH_SIZE = 32\n",
        "    NUM_EPOCHS = 100      # You set this to 20\n",
        "    LEARNING_RATE_G = 1e-4\n",
        "    LEARNING_RATE_D = 2e-4\n",
        "    BETA1 = 0.9\n",
        "    BETA2 = 0.999\n",
        "    LOG_INTERVAL = 10\n",
        "\n",
        "    SAVE_INTERVAL = 20 # Save every 20 epochs\n",
        "\n",
        "    # Add this line back!\n",
        "    SAVE_EPOCHS = [] # You can leave this empty if you only want to save every SAVE_INTERVAL epochs\n",
        "                     # Or populate it with specific epochs like [10, 50, 100, 150, 200]\n",
        "                     # for additional checkpoints.\n",
        "\n",
        "    # --- Loss Weights ---\n",
        "    LAMBDA_ADVERSARIAL = 1e-3\n",
        "    VGG_LAYER_FOR_LOSS = 'features.35'\n",
        "\n",
        "    # --- Device Configuration ---\n",
        "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # --- Paths for Checkpoints, History, and Results ---\n",
        "    CHECKPOINT_DIR = './checkpoints/'\n",
        "    HISTORY_FILE = './checkpoints/training_history.npz'\n",
        "    GENERATED_IMAGES_DIR = './results/generated_images/'\n",
        "    LOGS_DIR = './results/logs/'\n",
        "\n",
        "    # --- Paths for Image Generation ---\n",
        "    GENERATE_LR_DIR = './generate/low_res/'\n",
        "    GENERATE_HR_DIR = './generate/high_res/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mG6PurLnPGrV",
        "outputId": "bedfe31b-7d18-4551-ce67-807efc2fc18d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing src/config.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/models/generator.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class RRDB(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(RRDB, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n",
        "        self.relu = nn.LeakyReLU(0.2, inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.relu(self.conv1(x))\n",
        "        out = self.relu(self.conv2(out))\n",
        "        out = self.conv3(out)\n",
        "        return x + out\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, in_channels=3, num_rrdb=23):\n",
        "        super(Generator, self).__init__()\n",
        "        self.initial_conv = nn.Conv2d(in_channels, 64, kernel_size=3, padding=1)\n",
        "        self.relu = nn.LeakyReLU(0.2, inplace=True)\n",
        "        self.rrdb_blocks = nn.Sequential(*[RRDB(64) for _ in range(num_rrdb)])\n",
        "        self.upsample1 = nn.Sequential(\n",
        "            nn.Conv2d(64, 256, kernel_size=3, padding=1),\n",
        "            nn.PixelShuffle(2),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )\n",
        "        self.upsample2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 256, kernel_size=3, padding=1),\n",
        "            nn.PixelShuffle(2),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )\n",
        "        self.final_conv = nn.Conv2d(64, in_channels, kernel_size=3, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        initial_feature = self.relu(self.initial_conv(x))\n",
        "        out = self.rrdb_blocks(initial_feature)\n",
        "        out = initial_feature + out\n",
        "        out = self.upsample1(out)\n",
        "        out = self.upsample2(out)\n",
        "        out = self.final_conv(out)\n",
        "        return out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYca95y4PW_A",
        "outputId": "b2913fe0-1cb2-418c-d37a-8ae7421ccf7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing src/models/generator.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/models/discriminator.py\n",
        "import torch.nn as nn\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, in_channels=3):\n",
        "        super(Discriminator, self).__init__()\n",
        "        def block(in_feat, out_feat, normalize=True):\n",
        "            layers = [nn.Conv2d(in_feat, out_feat, kernel_size=4, stride=2, padding=1)]\n",
        "            if normalize:\n",
        "                layers.append(nn.BatchNorm2d(out_feat))\n",
        "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "            return layers\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            *block(in_channels, 64, normalize=False),\n",
        "            *block(64, 128),\n",
        "            *block(128, 256),\n",
        "            *block(256, 512),\n",
        "            nn.Conv2d(512, 1, kernel_size=3, stride=1, padding=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        return self.model(img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Aqs9Fe4Rsdo",
        "outputId": "aa2f30a4-b8f7-4bc1-b669-2888e7ce68f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing src/models/discriminator.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/utils/data_loader.py\n",
        "import os\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "class SRDataset(Dataset):\n",
        "    def __init__(self, lr_dir, hr_dir, transform=None):\n",
        "        self.lr_dir = lr_dir\n",
        "        self.hr_dir = hr_dir\n",
        "        self.transform = transform\n",
        "        self.image_pairs = []\n",
        "\n",
        "        lr_filenames = sorted([f for f in os.listdir(lr_dir) if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))])\n",
        "\n",
        "        for lr_fn in lr_filenames:\n",
        "            hr_fn = lr_fn.replace('x4', '')\n",
        "            hr_path = os.path.join(self.hr_dir, hr_fn)\n",
        "            if os.path.exists(hr_path):\n",
        "                self.image_pairs.append((lr_fn, hr_fn))\n",
        "\n",
        "        if not self.image_pairs:\n",
        "            raise FileNotFoundError(f\"No matching image pairs found between {lr_dir} and {hr_dir}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        lr_fn, hr_fn = self.image_pairs[idx]\n",
        "        lr_path = os.path.join(self.lr_dir, lr_fn)\n",
        "        hr_path = os.path.join(self.hr_dir, hr_fn)\n",
        "        lr_image = Image.open(lr_path).convert(\"RGB\")\n",
        "        hr_image = Image.open(hr_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            lr_image = self.transform['lr'](lr_image)\n",
        "            hr_image = self.transform['hr'](hr_image)\n",
        "        return lr_image, hr_image\n",
        "\n",
        "def get_dataloader(lr_dir, hr_dir, batch_size, shuffle, scale_factor=4, num_workers=2, pin_memory=True):\n",
        "    HR_IMAGE_SIZE = 256\n",
        "    LR_IMAGE_SIZE = HR_IMAGE_SIZE // scale_factor\n",
        "    hr_transform = transforms.Compose([\n",
        "        transforms.Resize((HR_IMAGE_SIZE, HR_IMAGE_SIZE)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "    lr_transform = transforms.Compose([\n",
        "        transforms.Resize((LR_IMAGE_SIZE, LR_IMAGE_SIZE)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "    transform_dict = {'hr': hr_transform, 'lr': lr_transform}\n",
        "    dataset = SRDataset(lr_dir=lr_dir, hr_dir=hr_dir, transform=transform_dict)\n",
        "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, pin_memory=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZdbPPKBPZi1",
        "outputId": "b5564a59-eb02-48e4-bc68-2ba270f52f20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing src/utils/data_loader.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/utils/losses.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "\n",
        "class ContentLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ContentLoss, self).__init__()\n",
        "    def forward(self, sr, hr):\n",
        "        return F.mse_loss(sr, hr)\n",
        "\n",
        "class PerceptualLoss(nn.Module):\n",
        "    def __init__(self, vgg_layer='features.35', device='cpu'):\n",
        "        super(PerceptualLoss, self).__init__()\n",
        "        vgg19 = models.vgg19(weights=models.VGG19_Weights.DEFAULT).features.to(device).eval()\n",
        "        for param in vgg19.parameters():\n",
        "            param.requires_grad = False\n",
        "        self.vgg_features = nn.Sequential(*list(vgg19.children())[:int(vgg_layer.split('.')[-1]) + 1])\n",
        "    def forward(self, sr, hr):\n",
        "        sr_features = self.vgg_features(sr)\n",
        "        hr_features = self.vgg_features(hr).detach()\n",
        "        return F.mse_loss(sr_features, hr_features)\n",
        "\n",
        "class DiscriminatorLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DiscriminatorLoss, self).__init__()\n",
        "        self.bce_loss = nn.BCEWithLogitsLoss()\n",
        "    def forward(self, real_output, fake_output):\n",
        "        real_loss = self.bce_loss(real_output, torch.ones_like(real_output))\n",
        "        fake_loss = self.bce_loss(fake_output, torch.zeros_like(fake_output))\n",
        "        return real_loss + fake_loss\n",
        "\n",
        "class GeneratorAdversarialLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GeneratorAdversarialLoss, self).__init__()\n",
        "        self.bce_loss = nn.BCEWithLogitsLoss()\n",
        "    def forward(self, fake_output):\n",
        "        return self.bce_loss(fake_output, torch.ones_like(fake_output))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzI3Pg7jPcMC",
        "outputId": "2ee58504-65b6-4279-dad8-7ba993f87c0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing src/utils/losses.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/utils/metrics.py\n",
        "import torch\n",
        "import numpy as np\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr_metric\n",
        "from skimage.metrics import structural_similarity as ssim_metric\n",
        "\n",
        "def calculate_psnr(img1, img2, data_range=1.0):\n",
        "    if isinstance(img1, torch.Tensor): img1 = img1.detach().cpu().numpy()\n",
        "    if isinstance(img2, torch.Tensor): img2 = img2.detach().cpu().numpy()\n",
        "    if img1.ndim == 4:\n",
        "        psnrs = [psnr_metric(img1[b].transpose(1, 2, 0), img2[b].transpose(1, 2, 0), data_range=data_range) for b in range(img1.shape[0])]\n",
        "        return np.mean(psnrs)\n",
        "    return psnr_metric(img1.transpose(1, 2, 0), img2.transpose(1, 2, 0), data_range=data_range)\n",
        "\n",
        "def calculate_ssim(img1, img2, data_range=1.0):\n",
        "    if isinstance(img1, torch.Tensor): img1 = img1.detach().cpu().numpy()\n",
        "    if isinstance(img2, torch.Tensor): img2 = img2.detach().cpu().numpy()\n",
        "    if img1.ndim == 4:\n",
        "        ssims = [ssim_metric(img1[b].transpose(1, 2, 0), img2[b].transpose(1, 2, 0), data_range=data_range, channel_axis=-1) for b in range(img1.shape[0])]\n",
        "        return np.mean(ssims)\n",
        "    return ssim_metric(img1.transpose(1, 2, 0), img2.transpose(1, 2, 0), data_range=data_range, channel_axis=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qt7p6UuAPebk",
        "outputId": "6821f297-3188-4eb6-cbe2-b258da6b1f09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing src/utils/metrics.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download HR training images\n",
        "!wget http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip -P ./data/\n",
        "\n",
        "# Download LR bicubic x4 training images\n",
        "!wget http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_LR_bicubic_X4.zip -P ./data/\n",
        "\n",
        "# Unzip files into the data directory\n",
        "!unzip -q ./data/DIV2K_train_HR.zip -d ./data/DIV2K/\n",
        "!unzip -q ./data/DIV2K_train_LR_bicubic_X4.zip -d ./data/DIV2K/\n",
        "\n",
        "# Clean up zip files\n",
        "!rm ./data/*.zip\n",
        "\n",
        "print(\"✅ Training dataset downloaded and prepared.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoK6G-tBPg-1",
        "outputId": "0024942f-f76e-4d39-fafe-67f4045853b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-24 17:12:49--  http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip\n",
            "Resolving data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)... 129.132.52.178, 2001:67c:10ec:36c2::178\n",
            "Connecting to data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)|129.132.52.178|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip [following]\n",
            "--2025-07-24 17:12:49--  https://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip\n",
            "Connecting to data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)|129.132.52.178|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3530603713 (3.3G) [application/zip]\n",
            "Saving to: ‘./data/DIV2K_train_HR.zip’\n",
            "\n",
            "DIV2K_train_HR.zip  100%[===================>]   3.29G  21.6MB/s    in 2m 38s  \n",
            "\n",
            "2025-07-24 17:15:28 (21.3 MB/s) - ‘./data/DIV2K_train_HR.zip’ saved [3530603713/3530603713]\n",
            "\n",
            "--2025-07-24 17:15:28--  http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_LR_bicubic_X4.zip\n",
            "Resolving data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)... 129.132.52.178, 2001:67c:10ec:36c2::178\n",
            "Connecting to data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)|129.132.52.178|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_LR_bicubic_X4.zip [following]\n",
            "--2025-07-24 17:15:28--  https://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_LR_bicubic_X4.zip\n",
            "Connecting to data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)|129.132.52.178|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 246914039 (235M) [application/zip]\n",
            "Saving to: ‘./data/DIV2K_train_LR_bicubic_X4.zip’\n",
            "\n",
            "DIV2K_train_LR_bicu 100%[===================>] 235.47M  22.0MB/s    in 12s     \n",
            "\n",
            "2025-07-24 17:15:41 (19.8 MB/s) - ‘./data/DIV2K_train_LR_bicubic_X4.zip’ saved [246914039/246914039]\n",
            "\n",
            "✅ Training dataset downloaded and prepared.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/train.py\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import os\n",
        "import numpy as np\n",
        "from torchvision.utils import save_image\n",
        "import torch.nn.functional as F\n",
        "from src.models.generator import Generator\n",
        "from src.models.discriminator import Discriminator\n",
        "from src.utils.data_loader import get_dataloader\n",
        "from src.utils.losses import ContentLoss, PerceptualLoss, DiscriminatorLoss, GeneratorAdversarialLoss\n",
        "from src.utils.metrics import calculate_psnr\n",
        "from src.config import Config\n",
        "\n",
        "def train_srgan():\n",
        "    # --- 1. INITIAL SETUP ---\n",
        "    config = Config()\n",
        "    device = config.DEVICE\n",
        "    start_epoch = 0\n",
        "    best_psnr = -1.0 # Initialize with a low value for PSNR to ensure first model is saved\n",
        "\n",
        "    os.makedirs(config.CHECKPOINT_DIR, exist_ok=True)\n",
        "    os.makedirs(config.GENERATED_IMAGES_DIR, exist_ok=True)\n",
        "    os.makedirs(config.LOGS_DIR, exist_ok=True)\n",
        "\n",
        "    # --- 2. INITIALIZE MODELS AND OPTIMIZERS ---\n",
        "    generator = Generator(in_channels=config.IN_CHANNELS, num_rrdb=config.NUM_RRDB_BLOCKS).to(device)\n",
        "    discriminator = Discriminator(in_channels=config.IN_CHANNELS).to(device)\n",
        "    optimizer_G = optim.Adam(generator.parameters(), lr=config.LEARNING_RATE_G, betas=(config.BETA1, config.BETA2))\n",
        "    optimizer_D = optim.Adam(discriminator.parameters(), lr=config.LEARNING_RATE_D, betas=(config.BETA1, config.BETA2))\n",
        "\n",
        "    g_loss_history, d_loss_history, psnr_history = [], [], []\n",
        "\n",
        "    # --- 3. RESUME FROM CHECKPOINT LOGIC ---\n",
        "    # Find the latest checkpoint (more robust than relying solely on history.npz)\n",
        "    latest_checkpoint_epoch = -1\n",
        "    latest_checkpoint_path = None\n",
        "    for f in os.listdir(config.CHECKPOINT_DIR):\n",
        "        if f.startswith(\"checkpoint_epoch_\") and f.endswith(\".pth\"):\n",
        "            try:\n",
        "                epoch_num = int(f.replace(\"checkpoint_epoch_\", \"\").replace(\".pth\", \"\"))\n",
        "                if epoch_num > latest_checkpoint_epoch:\n",
        "                    latest_checkpoint_epoch = epoch_num\n",
        "                    latest_checkpoint_path = os.path.join(config.CHECKPOINT_DIR, f)\n",
        "            except ValueError:\n",
        "                continue\n",
        "\n",
        "    if latest_checkpoint_path:\n",
        "        print(f\"=> Loading checkpoint from {latest_checkpoint_path}...\")\n",
        "        try:\n",
        "            checkpoint = torch.load(latest_checkpoint_path, map_location=device)\n",
        "            generator.load_state_dict(checkpoint['generator_state_dict'])\n",
        "            discriminator.load_state_dict(checkpoint['discriminator_state_dict'])\n",
        "            optimizer_G.load_state_dict(checkpoint['optimizer_G_state_dict'])\n",
        "            optimizer_D.load_state_dict(checkpoint['optimizer_D_state_dict'])\n",
        "            start_epoch = checkpoint['epoch'] + 1 # Start from the next epoch\n",
        "            g_loss_history = list(checkpoint['g_loss_history'])\n",
        "            d_loss_history = list(checkpoint['d_loss_history'])\n",
        "            psnr_history = list(checkpoint['psnr_history'])\n",
        "            best_psnr = checkpoint.get('best_psnr', -1.0) # Retrieve best_psnr if saved\n",
        "            print(f\"✅ Resuming training from epoch {start_epoch}\")\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error loading checkpoint {latest_checkpoint_path}: {e}\")\n",
        "            print(\"Starting training from scratch.\")\n",
        "            start_epoch = 0\n",
        "            g_loss_history, d_loss_history, psnr_history = [], [], []\n",
        "            best_psnr = -1.0 # Reset best_psnr if starting fresh\n",
        "    else:\n",
        "        print(\"No checkpoint found. Starting training from scratch.\")\n",
        "\n",
        "    # --- 4. LOSS FUNCTIONS AND DATALOADERS ---\n",
        "    content_criterion = ContentLoss().to(device)\n",
        "    perceptual_criterion = PerceptualLoss(vgg_layer=config.VGG_LAYER_FOR_LOSS, device=device)\n",
        "    discriminator_criterion = DiscriminatorLoss()\n",
        "    generator_adversarial_criterion = GeneratorAdversarialLoss()\n",
        "\n",
        "    train_dataloader = get_dataloader(\n",
        "        lr_dir=config.TRAIN_LR_DIR, hr_dir=config.TRAIN_HR_DIR,\n",
        "        batch_size=config.BATCH_SIZE, shuffle=True,\n",
        "        scale_factor=config.SCALE_FACTOR, num_workers=2\n",
        "    )\n",
        "    # Using a separate dataloader for sample image to avoid issues with batching\n",
        "    # when you only need one image.\n",
        "    sample_dataloader = get_dataloader(\n",
        "        lr_dir=config.TRAIN_LR_DIR, hr_dir=config.TRAIN_HR_DIR,\n",
        "        batch_size=1, shuffle=True,\n",
        "        scale_factor=config.SCALE_FACTOR, num_workers=1 # Using 1 worker for single image\n",
        "    )\n",
        "    sample_iterator = iter(sample_dataloader)\n",
        "\n",
        "    print(f\"🚀 Starting training from epoch {start_epoch}...\")\n",
        "\n",
        "    # --- 5. MAIN TRAINING LOOP ---\n",
        "    for epoch in range(start_epoch, config.NUM_EPOCHS):\n",
        "        epoch_g_loss = 0.0\n",
        "        epoch_d_loss = 0.0\n",
        "        generator.train()\n",
        "        discriminator.train()\n",
        "\n",
        "        for i, (lr_images, hr_images) in enumerate(train_dataloader):\n",
        "            lr_images, hr_images = lr_images.to(device), hr_images.to(device)\n",
        "\n",
        "            # --- Train Discriminator ---\n",
        "            optimizer_D.zero_grad()\n",
        "            real_preds = discriminator(hr_images)\n",
        "            sr_images = generator(lr_images).detach() # Detach to prevent gradients flowing to G\n",
        "            fake_preds = discriminator(sr_images)\n",
        "            d_loss = discriminator_criterion(real_preds, fake_preds)\n",
        "            d_loss.backward()\n",
        "            optimizer_D.step()\n",
        "\n",
        "            # --- Train Generator ---\n",
        "            optimizer_G.zero_grad()\n",
        "            sr_images_g = generator(lr_images)\n",
        "            fake_preds_g = discriminator(sr_images_g)\n",
        "            c_loss = content_criterion(sr_images_g, hr_images)\n",
        "            p_loss = perceptual_criterion(sr_images_g, hr_images)\n",
        "            adv_loss = generator_adversarial_criterion(fake_preds_g)\n",
        "            g_loss = c_loss + p_loss + config.LAMBDA_ADVERSARIAL * adv_loss\n",
        "            g_loss.backward()\n",
        "            optimizer_G.step()\n",
        "\n",
        "            epoch_g_loss += g_loss.item()\n",
        "            epoch_d_loss += d_loss.item()\n",
        "\n",
        "            if (i + 1) % config.LOG_INTERVAL == 0:\n",
        "                print(f\"E[{epoch+1}/{config.NUM_EPOCHS}] S[{i+1}/{len(train_dataloader)}] G_Loss:{g_loss.item():.4f} D_Loss:{d_loss.item():.4f}\")\n",
        "\n",
        "        # --- 6. END OF EPOCH: CALCULATE METRICS AND SAVE ---\n",
        "        avg_g_loss = epoch_g_loss / len(train_dataloader)\n",
        "        avg_d_loss = epoch_d_loss / len(train_dataloader)\n",
        "        g_loss_history.append(avg_g_loss)\n",
        "        d_loss_history.append(avg_d_loss)\n",
        "        print(f\"End of Epoch {epoch+1} | Avg. G_Loss: {avg_g_loss:.4f} | Avg. D_Loss: {avg_d_loss:.4f}\")\n",
        "\n",
        "        generator.eval()\n",
        "        with torch.no_grad():\n",
        "            try:\n",
        "                sample_lr, sample_hr = next(sample_iterator)\n",
        "            except StopIteration: # Reset iterator if exhausted\n",
        "                sample_iterator = iter(sample_dataloader)\n",
        "                sample_lr, sample_hr = next(sample_iterator)\n",
        "\n",
        "            sample_lr, sample_hr = sample_lr.to(device), sample_hr.to(device)\n",
        "            sr_output = generator(sample_lr)\n",
        "\n",
        "            # Denormalize images for PSNR calculation and saving\n",
        "            sr_unnorm = (sr_output + 1) / 2\n",
        "            hr_unnorm = (sample_hr + 1) / 2\n",
        "            current_psnr = calculate_psnr(sr_unnorm, hr_unnorm, data_range=1.0)\n",
        "            psnr_history.append(current_psnr)\n",
        "            print(f\"PSNR on sample image: {current_psnr:.4f} dB\")\n",
        "\n",
        "            save_image(sr_unnorm.cpu(), os.path.join(config.GENERATED_IMAGES_DIR, f\"epoch_{epoch+1}_sample.png\"))\n",
        "\n",
        "        # --- Checkpoint Saving Logic ---\n",
        "        # 1. Save every `SAVE_INTERVAL` epochs\n",
        "        # 2. Save at specific `SAVE_EPOCHS` (from config)\n",
        "        # 3. Always save the \"best\" model based on PSNR\n",
        "        # 4. Always save the history.npz file (as it's used by plot_results)\n",
        "\n",
        "        # Determine if we should save a periodic checkpoint\n",
        "        should_save_periodic = (epoch + 1) % config.SAVE_INTERVAL == 0\n",
        "\n",
        "        # Determine if we should save a specific checkpoint from the list\n",
        "        should_save_specific = (epoch + 1) in config.SAVE_EPOCHS\n",
        "\n",
        "        # Save a full checkpoint (models, optimizers, history)\n",
        "        if should_save_periodic or should_save_specific:\n",
        "            checkpoint_path = os.path.join(config.CHECKPOINT_DIR, f\"checkpoint_epoch_{epoch+1}.pth\")\n",
        "            print(f\"✅ Saving checkpoint for epoch {epoch+1}...\")\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'generator_state_dict': generator.state_dict(),\n",
        "                'discriminator_state_dict': discriminator.state_dict(),\n",
        "                'optimizer_G_state_dict': optimizer_G.state_dict(),\n",
        "                'optimizer_D_state_dict': optimizer_D.state_dict(),\n",
        "                'g_loss_history': g_loss_history,\n",
        "                'd_loss_history': d_loss_history,\n",
        "                'psnr_history': psnr_history,\n",
        "                'best_psnr': best_psnr, # Save current best_psnr\n",
        "            }, checkpoint_path)\n",
        "\n",
        "        # Save the best model based on PSNR (validation PSNR is usually better here)\n",
        "        if current_psnr > best_psnr:\n",
        "            best_psnr = current_psnr\n",
        "            best_model_path = os.path.join(config.CHECKPOINT_DIR, \"best_model.pth\")\n",
        "            print(f\"🌟 New best model found! Saving to {best_model_path} with PSNR: {best_psnr:.4f}\")\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'generator_state_dict': generator.state_dict(),\n",
        "                'best_psnr': best_psnr,\n",
        "            }, best_model_path) # Only save generator and best_psnr for simplicity of \"best model\"\n",
        "\n",
        "        # Always save the history file to track progress for resuming plot_results.py\n",
        "        np.savez(config.HISTORY_FILE,\n",
        "                 epoch=epoch + 1,\n",
        "                 g_loss=g_loss_history,\n",
        "                 d_loss=d_loss_history,\n",
        "                 psnr=psnr_history)\n",
        "\n",
        "    print(\"🏁 Finished Training!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train_srgan()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9G63QSWNPjqN",
        "outputId": "afb877a6-0b96-4d47-d0cc-5099bd0905a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing src/train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/plot_results.py\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from src.config import Config\n",
        "\n",
        "def plot_results():\n",
        "    config = Config()\n",
        "\n",
        "    if not os.path.exists(config.HISTORY_FILE):\n",
        "        print(f\"❌ History file not found at {config.HISTORY_FILE}\")\n",
        "        return\n",
        "\n",
        "    print(\"=> Loading history to plot graphs...\")\n",
        "    history = np.load(config.HISTORY_FILE)\n",
        "\n",
        "    g_loss_history = history['g_loss']\n",
        "    d_loss_history = history['d_loss']\n",
        "    psnr_history = history['psnr']\n",
        "    epochs_ran = int(history['epoch'])\n",
        "\n",
        "    if epochs_ran == 0:\n",
        "        print(\"No history found. Please train for at least one epoch.\")\n",
        "        return\n",
        "\n",
        "    # --- Plot 1: Training Losses ---\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(range(1, epochs_ran + 1), g_loss_history, label='Generator Loss', color='blue')\n",
        "    plt.plot(range(1, epochs_ran + 1), d_loss_history, label='Discriminator Loss', color='red')\n",
        "    plt.title('Training Losses')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Average Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    # --- Plot 2: PSNR ---\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(range(1, epochs_ran + 1), psnr_history, label='PSNR on Sample Image', color='green')\n",
        "    plt.title('PSNR')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('PSNR (dB)')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plot_path = os.path.join(config.LOGS_DIR, 'performance_graphs.png')\n",
        "    plt.savefig(plot_path)\n",
        "    print(f\"✅ Graphs saved to {plot_path}\")\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    plot_results()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjcHnX_BP_A5",
        "outputId": "614aac01-2953-4405-8ae4-64f32d793e03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing src/plot_results.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m src.train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBpAN5ArQDpG",
        "outputId": "70eba8a8-862c-438c-ffe5-acc418c37daa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No checkpoint found. Starting training from scratch.\n",
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n",
            "100% 548M/548M [00:03<00:00, 150MB/s]\n",
            "🚀 Starting training from epoch 0...\n",
            "E[1/100] S[10/25] G_Loss:0.5734 D_Loss:0.7654\n",
            "E[1/100] S[20/25] G_Loss:0.5494 D_Loss:0.4644\n",
            "End of Epoch 1 | Avg. G_Loss: 0.6042 | Avg. D_Loss: 0.7120\n",
            "PSNR on sample image: 14.7916 dB\n",
            "🌟 New best model found! Saving to ./checkpoints/best_model.pth with PSNR: 14.7916\n",
            "E[2/100] S[10/25] G_Loss:0.5329 D_Loss:0.2031\n",
            "E[2/100] S[20/25] G_Loss:0.4590 D_Loss:0.1835\n",
            "End of Epoch 2 | Avg. G_Loss: 0.5124 | Avg. D_Loss: 0.2143\n",
            "PSNR on sample image: 19.7775 dB\n",
            "🌟 New best model found! Saving to ./checkpoints/best_model.pth with PSNR: 19.7775\n",
            "E[3/100] S[10/25] G_Loss:0.4985 D_Loss:0.1114\n",
            "E[3/100] S[20/25] G_Loss:0.4661 D_Loss:0.0829\n",
            "End of Epoch 3 | Avg. G_Loss: 0.4874 | Avg. D_Loss: 0.1088\n",
            "PSNR on sample image: 21.0533 dB\n",
            "🌟 New best model found! Saving to ./checkpoints/best_model.pth with PSNR: 21.0533\n",
            "E[4/100] S[10/25] G_Loss:0.4497 D_Loss:0.0420\n",
            "E[4/100] S[20/25] G_Loss:0.5019 D_Loss:0.0358\n",
            "End of Epoch 4 | Avg. G_Loss: 0.4769 | Avg. D_Loss: 0.0426\n",
            "PSNR on sample image: 19.1163 dB\n",
            "E[5/100] S[10/25] G_Loss:0.4716 D_Loss:0.0273\n",
            "E[5/100] S[20/25] G_Loss:0.4338 D_Loss:0.0253\n",
            "End of Epoch 5 | Avg. G_Loss: 0.4670 | Avg. D_Loss: 0.0268\n",
            "PSNR on sample image: 25.0786 dB\n",
            "🌟 New best model found! Saving to ./checkpoints/best_model.pth with PSNR: 25.0786\n",
            "E[6/100] S[10/25] G_Loss:0.4470 D_Loss:0.0248\n",
            "E[6/100] S[20/25] G_Loss:0.4598 D_Loss:0.0228\n",
            "End of Epoch 6 | Avg. G_Loss: 0.4518 | Avg. D_Loss: 0.0226\n",
            "PSNR on sample image: 18.2086 dB\n",
            "E[7/100] S[10/25] G_Loss:0.4581 D_Loss:0.0284\n",
            "E[7/100] S[20/25] G_Loss:0.3840 D_Loss:0.0205\n",
            "End of Epoch 7 | Avg. G_Loss: 0.4240 | Avg. D_Loss: 0.0259\n",
            "PSNR on sample image: 26.8867 dB\n",
            "🌟 New best model found! Saving to ./checkpoints/best_model.pth with PSNR: 26.8867\n",
            "E[8/100] S[10/25] G_Loss:0.3821 D_Loss:0.0154\n",
            "E[8/100] S[20/25] G_Loss:0.3811 D_Loss:0.0134\n",
            "End of Epoch 8 | Avg. G_Loss: 0.3999 | Avg. D_Loss: 0.0166\n",
            "PSNR on sample image: 24.1767 dB\n",
            "E[9/100] S[10/25] G_Loss:0.3835 D_Loss:0.0116\n",
            "E[9/100] S[20/25] G_Loss:0.3738 D_Loss:0.0095\n",
            "End of Epoch 9 | Avg. G_Loss: 0.3836 | Avg. D_Loss: 0.0111\n",
            "PSNR on sample image: 23.2632 dB\n",
            "E[10/100] S[10/25] G_Loss:0.3662 D_Loss:0.0124\n",
            "E[10/100] S[20/25] G_Loss:0.4299 D_Loss:0.0068\n",
            "End of Epoch 10 | Avg. G_Loss: 0.3702 | Avg. D_Loss: 0.0090\n",
            "PSNR on sample image: 22.1476 dB\n",
            "E[11/100] S[10/25] G_Loss:0.3812 D_Loss:0.0075\n",
            "E[11/100] S[20/25] G_Loss:0.4178 D_Loss:0.0058\n",
            "End of Epoch 11 | Avg. G_Loss: 0.3600 | Avg. D_Loss: 0.0068\n",
            "PSNR on sample image: 25.7784 dB\n",
            "E[12/100] S[10/25] G_Loss:0.3173 D_Loss:0.0067\n",
            "E[12/100] S[20/25] G_Loss:0.3949 D_Loss:0.0051\n",
            "End of Epoch 12 | Avg. G_Loss: 0.3521 | Avg. D_Loss: 0.0057\n",
            "PSNR on sample image: 20.8260 dB\n",
            "E[13/100] S[10/25] G_Loss:0.3014 D_Loss:0.0046\n",
            "E[13/100] S[20/25] G_Loss:0.3318 D_Loss:0.0048\n",
            "End of Epoch 13 | Avg. G_Loss: 0.3445 | Avg. D_Loss: 0.0050\n",
            "PSNR on sample image: 21.8669 dB\n",
            "E[14/100] S[10/25] G_Loss:0.3293 D_Loss:0.0041\n",
            "E[14/100] S[20/25] G_Loss:0.3149 D_Loss:0.0042\n",
            "End of Epoch 14 | Avg. G_Loss: 0.3379 | Avg. D_Loss: 0.0043\n",
            "PSNR on sample image: 22.4941 dB\n",
            "E[15/100] S[10/25] G_Loss:0.2907 D_Loss:0.0037\n",
            "E[15/100] S[20/25] G_Loss:0.3082 D_Loss:0.0032\n",
            "End of Epoch 15 | Avg. G_Loss: 0.3320 | Avg. D_Loss: 0.0038\n",
            "PSNR on sample image: 21.0542 dB\n",
            "E[16/100] S[10/25] G_Loss:0.2785 D_Loss:0.0032\n",
            "E[16/100] S[20/25] G_Loss:0.3482 D_Loss:0.0031\n",
            "End of Epoch 16 | Avg. G_Loss: 0.3265 | Avg. D_Loss: 0.0033\n",
            "PSNR on sample image: 22.6359 dB\n",
            "E[17/100] S[10/25] G_Loss:0.2919 D_Loss:0.0027\n",
            "E[17/100] S[20/25] G_Loss:0.3391 D_Loss:0.0028\n",
            "End of Epoch 17 | Avg. G_Loss: 0.3224 | Avg. D_Loss: 0.0031\n",
            "PSNR on sample image: 25.9096 dB\n",
            "E[18/100] S[10/25] G_Loss:0.3167 D_Loss:0.0025\n",
            "E[18/100] S[20/25] G_Loss:0.3350 D_Loss:0.0027\n",
            "End of Epoch 18 | Avg. G_Loss: 0.3176 | Avg. D_Loss: 0.0027\n",
            "PSNR on sample image: 23.7972 dB\n",
            "E[19/100] S[10/25] G_Loss:0.3537 D_Loss:0.0022\n",
            "E[19/100] S[20/25] G_Loss:0.3265 D_Loss:0.0022\n",
            "End of Epoch 19 | Avg. G_Loss: 0.3134 | Avg. D_Loss: 0.0025\n",
            "PSNR on sample image: 21.2737 dB\n",
            "E[20/100] S[10/25] G_Loss:0.2846 D_Loss:0.0023\n",
            "E[20/100] S[20/25] G_Loss:0.3239 D_Loss:0.0025\n",
            "End of Epoch 20 | Avg. G_Loss: 0.3098 | Avg. D_Loss: 0.0024\n",
            "PSNR on sample image: 21.0769 dB\n",
            "✅ Saving checkpoint for epoch 20...\n",
            "E[21/100] S[10/25] G_Loss:0.3110 D_Loss:0.0024\n",
            "E[21/100] S[20/25] G_Loss:0.3005 D_Loss:0.0021\n",
            "End of Epoch 21 | Avg. G_Loss: 0.3061 | Avg. D_Loss: 0.0020\n",
            "PSNR on sample image: 20.8416 dB\n",
            "E[22/100] S[10/25] G_Loss:0.3246 D_Loss:0.0018\n",
            "E[22/100] S[20/25] G_Loss:0.3219 D_Loss:0.0019\n",
            "End of Epoch 22 | Avg. G_Loss: 0.3026 | Avg. D_Loss: 0.0019\n",
            "PSNR on sample image: 26.5587 dB\n",
            "E[23/100] S[10/25] G_Loss:0.3599 D_Loss:0.0019\n",
            "E[23/100] S[20/25] G_Loss:0.2995 D_Loss:0.0016\n",
            "End of Epoch 23 | Avg. G_Loss: 0.2996 | Avg. D_Loss: 0.0018\n",
            "PSNR on sample image: 22.5244 dB\n",
            "E[24/100] S[10/25] G_Loss:0.3167 D_Loss:0.0016\n",
            "E[24/100] S[20/25] G_Loss:0.2756 D_Loss:0.0016\n",
            "End of Epoch 24 | Avg. G_Loss: 0.2961 | Avg. D_Loss: 0.0016\n",
            "PSNR on sample image: 21.8456 dB\n",
            "E[25/100] S[10/25] G_Loss:0.2445 D_Loss:0.0014\n",
            "E[25/100] S[20/25] G_Loss:0.3055 D_Loss:0.0014\n",
            "End of Epoch 25 | Avg. G_Loss: 0.2927 | Avg. D_Loss: 0.0015\n",
            "PSNR on sample image: 23.8541 dB\n",
            "E[26/100] S[10/25] G_Loss:0.2899 D_Loss:0.0015\n",
            "E[26/100] S[20/25] G_Loss:0.2950 D_Loss:0.0014\n",
            "End of Epoch 26 | Avg. G_Loss: 0.2892 | Avg. D_Loss: 0.0015\n",
            "PSNR on sample image: 23.5274 dB\n",
            "E[27/100] S[10/25] G_Loss:0.2528 D_Loss:0.0012\n",
            "E[27/100] S[20/25] G_Loss:0.3094 D_Loss:0.0014\n",
            "End of Epoch 27 | Avg. G_Loss: 0.2864 | Avg. D_Loss: 0.0013\n",
            "PSNR on sample image: 23.0565 dB\n",
            "E[28/100] S[10/25] G_Loss:0.2622 D_Loss:0.0012\n",
            "E[28/100] S[20/25] G_Loss:0.2401 D_Loss:0.0012\n",
            "End of Epoch 28 | Avg. G_Loss: 0.2836 | Avg. D_Loss: 0.0013\n",
            "PSNR on sample image: 22.7449 dB\n",
            "E[29/100] S[10/25] G_Loss:0.2603 D_Loss:0.0012\n",
            "E[29/100] S[20/25] G_Loss:0.2743 D_Loss:0.0012\n",
            "End of Epoch 29 | Avg. G_Loss: 0.2802 | Avg. D_Loss: 0.0012\n",
            "PSNR on sample image: 22.4670 dB\n",
            "E[30/100] S[10/25] G_Loss:0.2854 D_Loss:0.0011\n",
            "E[30/100] S[20/25] G_Loss:0.2519 D_Loss:0.0011\n",
            "End of Epoch 30 | Avg. G_Loss: 0.2774 | Avg. D_Loss: 0.0011\n",
            "PSNR on sample image: 23.3511 dB\n",
            "E[31/100] S[10/25] G_Loss:0.2821 D_Loss:0.0011\n",
            "E[31/100] S[20/25] G_Loss:0.2707 D_Loss:0.0011\n",
            "End of Epoch 31 | Avg. G_Loss: 0.2743 | Avg. D_Loss: 0.0011\n",
            "PSNR on sample image: 26.6512 dB\n",
            "E[32/100] S[10/25] G_Loss:0.2711 D_Loss:0.0011\n",
            "E[32/100] S[20/25] G_Loss:0.2784 D_Loss:0.0010\n",
            "End of Epoch 32 | Avg. G_Loss: 0.2724 | Avg. D_Loss: 0.0010\n",
            "PSNR on sample image: 26.4966 dB\n",
            "E[33/100] S[10/25] G_Loss:0.2867 D_Loss:0.0009\n",
            "E[33/100] S[20/25] G_Loss:0.2533 D_Loss:0.0010\n",
            "End of Epoch 33 | Avg. G_Loss: 0.2685 | Avg. D_Loss: 0.0009\n",
            "PSNR on sample image: 25.8438 dB\n",
            "E[34/100] S[10/25] G_Loss:0.2574 D_Loss:0.0009\n",
            "E[34/100] S[20/25] G_Loss:0.2608 D_Loss:0.0009\n",
            "End of Epoch 34 | Avg. G_Loss: 0.2647 | Avg. D_Loss: 0.0009\n",
            "PSNR on sample image: 19.5639 dB\n",
            "E[35/100] S[10/25] G_Loss:0.2869 D_Loss:0.0008\n",
            "E[35/100] S[20/25] G_Loss:0.3192 D_Loss:0.0008\n",
            "End of Epoch 35 | Avg. G_Loss: 0.2626 | Avg. D_Loss: 0.0009\n",
            "PSNR on sample image: 26.6477 dB\n",
            "E[36/100] S[10/25] G_Loss:0.2790 D_Loss:0.0009\n",
            "E[36/100] S[20/25] G_Loss:0.2493 D_Loss:0.0008\n",
            "End of Epoch 36 | Avg. G_Loss: 0.2600 | Avg. D_Loss: 0.0008\n",
            "PSNR on sample image: 20.7354 dB\n",
            "E[37/100] S[10/25] G_Loss:0.2432 D_Loss:0.0008\n",
            "E[37/100] S[20/25] G_Loss:0.2654 D_Loss:0.0007\n",
            "End of Epoch 37 | Avg. G_Loss: 0.2557 | Avg. D_Loss: 0.0008\n",
            "PSNR on sample image: 20.8207 dB\n",
            "E[38/100] S[10/25] G_Loss:0.2405 D_Loss:0.0007\n",
            "E[38/100] S[20/25] G_Loss:0.2173 D_Loss:0.0007\n",
            "End of Epoch 38 | Avg. G_Loss: 0.2515 | Avg. D_Loss: 0.0008\n",
            "PSNR on sample image: 23.0550 dB\n",
            "E[39/100] S[10/25] G_Loss:0.2548 D_Loss:0.0007\n",
            "E[39/100] S[20/25] G_Loss:0.2696 D_Loss:0.0008\n",
            "End of Epoch 39 | Avg. G_Loss: 0.2481 | Avg. D_Loss: 0.0007\n",
            "PSNR on sample image: 27.1674 dB\n",
            "🌟 New best model found! Saving to ./checkpoints/best_model.pth with PSNR: 27.1674\n",
            "E[40/100] S[10/25] G_Loss:0.2435 D_Loss:0.0007\n",
            "E[40/100] S[20/25] G_Loss:0.2421 D_Loss:0.0007\n",
            "End of Epoch 40 | Avg. G_Loss: 0.2455 | Avg. D_Loss: 0.0007\n",
            "PSNR on sample image: 25.2912 dB\n",
            "✅ Saving checkpoint for epoch 40...\n",
            "E[41/100] S[10/25] G_Loss:0.2238 D_Loss:0.0007\n",
            "E[41/100] S[20/25] G_Loss:0.2808 D_Loss:0.0010\n",
            "End of Epoch 41 | Avg. G_Loss: 0.2417 | Avg. D_Loss: 0.0007\n",
            "PSNR on sample image: 21.9833 dB\n",
            "E[42/100] S[10/25] G_Loss:0.2232 D_Loss:0.0006\n",
            "E[42/100] S[20/25] G_Loss:0.2524 D_Loss:0.0007\n",
            "End of Epoch 42 | Avg. G_Loss: 0.2391 | Avg. D_Loss: 0.0007\n",
            "PSNR on sample image: 21.3322 dB\n",
            "E[43/100] S[10/25] G_Loss:0.2351 D_Loss:0.0006\n",
            "E[43/100] S[20/25] G_Loss:0.2424 D_Loss:0.0006\n",
            "End of Epoch 43 | Avg. G_Loss: 0.2363 | Avg. D_Loss: 0.0006\n",
            "PSNR on sample image: 24.7887 dB\n",
            "E[44/100] S[10/25] G_Loss:0.2151 D_Loss:0.0006\n",
            "E[44/100] S[20/25] G_Loss:0.2555 D_Loss:0.0007\n",
            "End of Epoch 44 | Avg. G_Loss: 0.2331 | Avg. D_Loss: 0.0006\n",
            "PSNR on sample image: 25.2830 dB\n",
            "E[45/100] S[10/25] G_Loss:0.2349 D_Loss:0.0007\n",
            "E[45/100] S[20/25] G_Loss:0.2201 D_Loss:0.0007\n",
            "End of Epoch 45 | Avg. G_Loss: 0.2304 | Avg. D_Loss: 0.0006\n",
            "PSNR on sample image: 25.3290 dB\n",
            "E[46/100] S[10/25] G_Loss:0.2352 D_Loss:0.0006\n",
            "E[46/100] S[20/25] G_Loss:0.2294 D_Loss:0.0006\n",
            "End of Epoch 46 | Avg. G_Loss: 0.2266 | Avg. D_Loss: 0.0006\n",
            "PSNR on sample image: 24.3938 dB\n",
            "E[47/100] S[10/25] G_Loss:0.2292 D_Loss:0.0005\n",
            "E[47/100] S[20/25] G_Loss:0.2247 D_Loss:0.0005\n",
            "End of Epoch 47 | Avg. G_Loss: 0.2239 | Avg. D_Loss: 0.0005\n",
            "PSNR on sample image: 21.6342 dB\n",
            "E[48/100] S[10/25] G_Loss:0.2284 D_Loss:0.0006\n",
            "E[48/100] S[20/25] G_Loss:0.2134 D_Loss:0.0005\n",
            "End of Epoch 48 | Avg. G_Loss: 0.2206 | Avg. D_Loss: 0.0005\n",
            "PSNR on sample image: 23.2132 dB\n",
            "E[49/100] S[10/25] G_Loss:0.2384 D_Loss:0.0005\n",
            "E[49/100] S[20/25] G_Loss:0.2218 D_Loss:0.0005\n",
            "End of Epoch 49 | Avg. G_Loss: 0.2180 | Avg. D_Loss: 0.0005\n",
            "PSNR on sample image: 24.6140 dB\n",
            "E[50/100] S[10/25] G_Loss:0.2174 D_Loss:0.0005\n",
            "E[50/100] S[20/25] G_Loss:0.1992 D_Loss:0.0005\n",
            "End of Epoch 50 | Avg. G_Loss: 0.2156 | Avg. D_Loss: 0.0005\n",
            "PSNR on sample image: 22.6344 dB\n",
            "E[51/100] S[10/25] G_Loss:0.2121 D_Loss:0.0004\n",
            "E[51/100] S[20/25] G_Loss:0.2112 D_Loss:0.0004\n",
            "End of Epoch 51 | Avg. G_Loss: 0.2133 | Avg. D_Loss: 0.0005\n",
            "PSNR on sample image: 20.6889 dB\n",
            "E[52/100] S[10/25] G_Loss:0.2146 D_Loss:0.0005\n",
            "E[52/100] S[20/25] G_Loss:0.1882 D_Loss:0.0005\n",
            "End of Epoch 52 | Avg. G_Loss: 0.2115 | Avg. D_Loss: 0.0005\n",
            "PSNR on sample image: 22.4526 dB\n",
            "E[53/100] S[10/25] G_Loss:0.2047 D_Loss:0.0004\n",
            "E[53/100] S[20/25] G_Loss:0.2250 D_Loss:0.0005\n",
            "End of Epoch 53 | Avg. G_Loss: 0.2072 | Avg. D_Loss: 0.0005\n",
            "PSNR on sample image: 26.8448 dB\n",
            "E[54/100] S[10/25] G_Loss:0.1979 D_Loss:0.0004\n",
            "E[54/100] S[20/25] G_Loss:0.2058 D_Loss:0.0005\n",
            "End of Epoch 54 | Avg. G_Loss: 0.2053 | Avg. D_Loss: 0.0005\n",
            "PSNR on sample image: 21.6223 dB\n",
            "E[55/100] S[10/25] G_Loss:0.2185 D_Loss:0.0004\n",
            "E[55/100] S[20/25] G_Loss:0.2170 D_Loss:0.0004\n",
            "End of Epoch 55 | Avg. G_Loss: 0.2036 | Avg. D_Loss: 0.0004\n",
            "PSNR on sample image: 24.3487 dB\n",
            "E[56/100] S[10/25] G_Loss:0.2127 D_Loss:0.0004\n",
            "E[56/100] S[20/25] G_Loss:0.2107 D_Loss:0.0003\n",
            "End of Epoch 56 | Avg. G_Loss: 0.2004 | Avg. D_Loss: 0.0004\n",
            "PSNR on sample image: 27.3385 dB\n",
            "🌟 New best model found! Saving to ./checkpoints/best_model.pth with PSNR: 27.3385\n",
            "E[57/100] S[10/25] G_Loss:0.1925 D_Loss:0.0004\n",
            "E[57/100] S[20/25] G_Loss:0.2285 D_Loss:0.0005\n",
            "End of Epoch 57 | Avg. G_Loss: 0.1987 | Avg. D_Loss: 0.0004\n",
            "PSNR on sample image: 21.5492 dB\n",
            "E[58/100] S[10/25] G_Loss:0.2112 D_Loss:0.0004\n",
            "E[58/100] S[20/25] G_Loss:0.2305 D_Loss:0.0004\n",
            "End of Epoch 58 | Avg. G_Loss: 0.1966 | Avg. D_Loss: 0.0004\n",
            "PSNR on sample image: 25.2766 dB\n",
            "E[59/100] S[10/25] G_Loss:0.1898 D_Loss:0.0003\n",
            "E[59/100] S[20/25] G_Loss:0.2058 D_Loss:0.0003\n",
            "End of Epoch 59 | Avg. G_Loss: 0.1949 | Avg. D_Loss: 0.0004\n",
            "PSNR on sample image: 23.0389 dB\n",
            "E[60/100] S[10/25] G_Loss:0.2079 D_Loss:0.0004\n",
            "E[60/100] S[20/25] G_Loss:0.2079 D_Loss:0.0003\n",
            "End of Epoch 60 | Avg. G_Loss: 0.1927 | Avg. D_Loss: 0.0004\n",
            "PSNR on sample image: 21.8218 dB\n",
            "✅ Saving checkpoint for epoch 60...\n",
            "E[61/100] S[10/25] G_Loss:0.1839 D_Loss:0.0003\n",
            "E[61/100] S[20/25] G_Loss:0.1781 D_Loss:0.0004\n",
            "End of Epoch 61 | Avg. G_Loss: 0.1906 | Avg. D_Loss: 0.0004\n",
            "PSNR on sample image: 22.7195 dB\n",
            "E[62/100] S[10/25] G_Loss:0.1937 D_Loss:0.0004\n",
            "E[62/100] S[20/25] G_Loss:0.1693 D_Loss:5.3006\n",
            "End of Epoch 62 | Avg. G_Loss: 0.1853 | Avg. D_Loss: 1.1590\n",
            "PSNR on sample image: 20.9667 dB\n",
            "E[63/100] S[10/25] G_Loss:0.1802 D_Loss:1.3312\n",
            "E[63/100] S[20/25] G_Loss:0.1653 D_Loss:1.1727\n",
            "End of Epoch 63 | Avg. G_Loss: 0.1777 | Avg. D_Loss: 1.2869\n",
            "PSNR on sample image: 22.1181 dB\n",
            "E[64/100] S[10/25] G_Loss:0.1733 D_Loss:0.5773\n",
            "E[64/100] S[20/25] G_Loss:0.1715 D_Loss:0.1876\n",
            "End of Epoch 64 | Avg. G_Loss: 0.1772 | Avg. D_Loss: 0.4877\n",
            "PSNR on sample image: 27.2947 dB\n",
            "E[65/100] S[10/25] G_Loss:0.1797 D_Loss:0.0417\n",
            "E[65/100] S[20/25] G_Loss:0.1716 D_Loss:0.0211\n",
            "End of Epoch 65 | Avg. G_Loss: 0.1773 | Avg. D_Loss: 0.0493\n",
            "PSNR on sample image: 23.5443 dB\n",
            "E[66/100] S[10/25] G_Loss:0.1734 D_Loss:0.0134\n",
            "E[66/100] S[20/25] G_Loss:0.1692 D_Loss:0.0109\n",
            "End of Epoch 66 | Avg. G_Loss: 0.1765 | Avg. D_Loss: 0.0136\n",
            "PSNR on sample image: 21.5146 dB\n",
            "E[67/100] S[10/25] G_Loss:0.1729 D_Loss:0.0093\n",
            "E[67/100] S[20/25] G_Loss:0.1747 D_Loss:0.0085\n",
            "End of Epoch 67 | Avg. G_Loss: 0.1755 | Avg. D_Loss: 0.0082\n",
            "PSNR on sample image: 20.3736 dB\n",
            "E[68/100] S[10/25] G_Loss:0.1688 D_Loss:0.0062\n",
            "E[68/100] S[20/25] G_Loss:0.1688 D_Loss:0.0053\n",
            "End of Epoch 68 | Avg. G_Loss: 0.1741 | Avg. D_Loss: 0.0061\n",
            "PSNR on sample image: 24.6016 dB\n",
            "E[69/100] S[10/25] G_Loss:0.1834 D_Loss:0.0056\n",
            "E[69/100] S[20/25] G_Loss:0.1734 D_Loss:0.0051\n",
            "End of Epoch 69 | Avg. G_Loss: 0.1723 | Avg. D_Loss: 0.0051\n",
            "PSNR on sample image: 18.7240 dB\n",
            "E[70/100] S[10/25] G_Loss:0.1820 D_Loss:0.0044\n",
            "E[70/100] S[20/25] G_Loss:0.1677 D_Loss:0.0043\n",
            "End of Epoch 70 | Avg. G_Loss: 0.1717 | Avg. D_Loss: 0.0044\n",
            "PSNR on sample image: 27.3693 dB\n",
            "🌟 New best model found! Saving to ./checkpoints/best_model.pth with PSNR: 27.3693\n",
            "E[71/100] S[10/25] G_Loss:0.1816 D_Loss:0.0040\n",
            "E[71/100] S[20/25] G_Loss:0.1712 D_Loss:0.0033\n",
            "End of Epoch 71 | Avg. G_Loss: 0.1707 | Avg. D_Loss: 0.0041\n",
            "PSNR on sample image: 26.0373 dB\n",
            "E[72/100] S[10/25] G_Loss:0.1682 D_Loss:0.0036\n",
            "E[72/100] S[20/25] G_Loss:0.1600 D_Loss:0.0039\n",
            "End of Epoch 72 | Avg. G_Loss: 0.1683 | Avg. D_Loss: 0.0035\n",
            "PSNR on sample image: 22.4557 dB\n",
            "E[73/100] S[10/25] G_Loss:0.1743 D_Loss:0.0029\n",
            "E[73/100] S[20/25] G_Loss:0.1732 D_Loss:0.0031\n",
            "End of Epoch 73 | Avg. G_Loss: 0.1672 | Avg. D_Loss: 0.0031\n",
            "PSNR on sample image: 20.4146 dB\n",
            "E[74/100] S[10/25] G_Loss:0.1672 D_Loss:0.0030\n",
            "E[74/100] S[20/25] G_Loss:0.1522 D_Loss:0.0030\n",
            "End of Epoch 74 | Avg. G_Loss: 0.1657 | Avg. D_Loss: 0.0030\n",
            "PSNR on sample image: 22.7153 dB\n",
            "E[75/100] S[10/25] G_Loss:0.1653 D_Loss:0.0032\n",
            "E[75/100] S[20/25] G_Loss:0.1534 D_Loss:0.0023\n",
            "End of Epoch 75 | Avg. G_Loss: 0.1641 | Avg. D_Loss: 0.0027\n",
            "PSNR on sample image: 26.5968 dB\n",
            "E[76/100] S[10/25] G_Loss:0.1572 D_Loss:0.0030\n",
            "E[76/100] S[20/25] G_Loss:0.1671 D_Loss:0.0025\n",
            "End of Epoch 76 | Avg. G_Loss: 0.1628 | Avg. D_Loss: 0.0025\n",
            "PSNR on sample image: 23.1336 dB\n",
            "E[77/100] S[10/25] G_Loss:0.1598 D_Loss:0.0021\n",
            "E[77/100] S[20/25] G_Loss:0.1604 D_Loss:0.0021\n",
            "End of Epoch 77 | Avg. G_Loss: 0.1613 | Avg. D_Loss: 0.0023\n",
            "PSNR on sample image: 23.2443 dB\n",
            "E[78/100] S[10/25] G_Loss:0.1658 D_Loss:0.0025\n",
            "E[78/100] S[20/25] G_Loss:0.1639 D_Loss:0.0019\n",
            "End of Epoch 78 | Avg. G_Loss: 0.1608 | Avg. D_Loss: 0.0023\n",
            "PSNR on sample image: 20.3934 dB\n",
            "E[79/100] S[10/25] G_Loss:0.1510 D_Loss:0.0020\n",
            "E[79/100] S[20/25] G_Loss:0.1518 D_Loss:0.0017\n",
            "End of Epoch 79 | Avg. G_Loss: 0.1590 | Avg. D_Loss: 0.0021\n",
            "PSNR on sample image: 21.6766 dB\n",
            "E[80/100] S[10/25] G_Loss:0.1578 D_Loss:0.0020\n",
            "E[80/100] S[20/25] G_Loss:0.1690 D_Loss:0.0018\n",
            "End of Epoch 80 | Avg. G_Loss: 0.1587 | Avg. D_Loss: 0.0019\n",
            "PSNR on sample image: 22.5335 dB\n",
            "✅ Saving checkpoint for epoch 80...\n",
            "E[81/100] S[10/25] G_Loss:0.1729 D_Loss:0.0017\n",
            "E[81/100] S[20/25] G_Loss:0.1774 D_Loss:0.0022\n",
            "End of Epoch 81 | Avg. G_Loss: 0.1574 | Avg. D_Loss: 0.0019\n",
            "PSNR on sample image: 20.7432 dB\n",
            "E[82/100] S[10/25] G_Loss:0.1897 D_Loss:0.0018\n",
            "E[82/100] S[20/25] G_Loss:0.1571 D_Loss:0.0019\n",
            "End of Epoch 82 | Avg. G_Loss: 0.1560 | Avg. D_Loss: 0.0018\n",
            "PSNR on sample image: 21.8056 dB\n",
            "E[83/100] S[10/25] G_Loss:0.1592 D_Loss:0.0017\n",
            "E[83/100] S[20/25] G_Loss:0.1299 D_Loss:0.0019\n",
            "End of Epoch 83 | Avg. G_Loss: 0.1552 | Avg. D_Loss: 0.0018\n",
            "PSNR on sample image: 21.4336 dB\n",
            "E[84/100] S[10/25] G_Loss:0.1605 D_Loss:0.0019\n",
            "E[84/100] S[20/25] G_Loss:0.1670 D_Loss:0.0017\n",
            "End of Epoch 84 | Avg. G_Loss: 0.1544 | Avg. D_Loss: 0.0017\n",
            "PSNR on sample image: 19.2509 dB\n",
            "E[85/100] S[10/25] G_Loss:0.1625 D_Loss:0.0017\n",
            "E[85/100] S[20/25] G_Loss:0.1559 D_Loss:0.0012\n",
            "End of Epoch 85 | Avg. G_Loss: 0.1536 | Avg. D_Loss: 0.0016\n",
            "PSNR on sample image: 20.2765 dB\n",
            "E[86/100] S[10/25] G_Loss:0.1742 D_Loss:0.0020\n",
            "E[86/100] S[20/25] G_Loss:0.1484 D_Loss:0.0016\n",
            "End of Epoch 86 | Avg. G_Loss: 0.1511 | Avg. D_Loss: 0.0015\n",
            "PSNR on sample image: 27.7898 dB\n",
            "🌟 New best model found! Saving to ./checkpoints/best_model.pth with PSNR: 27.7898\n",
            "E[87/100] S[10/25] G_Loss:0.1366 D_Loss:0.0013\n",
            "E[87/100] S[20/25] G_Loss:0.1564 D_Loss:0.0012\n",
            "End of Epoch 87 | Avg. G_Loss: 0.1502 | Avg. D_Loss: 0.0015\n",
            "PSNR on sample image: 21.2229 dB\n",
            "E[88/100] S[10/25] G_Loss:0.1503 D_Loss:0.0013\n",
            "E[88/100] S[20/25] G_Loss:0.1432 D_Loss:0.0016\n",
            "End of Epoch 88 | Avg. G_Loss: 0.1490 | Avg. D_Loss: 0.0014\n",
            "PSNR on sample image: 24.6212 dB\n",
            "E[89/100] S[10/25] G_Loss:0.1455 D_Loss:0.0015\n",
            "E[89/100] S[20/25] G_Loss:0.1444 D_Loss:0.0016\n",
            "End of Epoch 89 | Avg. G_Loss: 0.1472 | Avg. D_Loss: 0.0014\n",
            "PSNR on sample image: 20.1452 dB\n",
            "E[90/100] S[10/25] G_Loss:0.1517 D_Loss:0.0016\n",
            "E[90/100] S[20/25] G_Loss:0.1461 D_Loss:0.0014\n",
            "End of Epoch 90 | Avg. G_Loss: 0.1466 | Avg. D_Loss: 0.0014\n",
            "PSNR on sample image: 21.2443 dB\n",
            "E[91/100] S[10/25] G_Loss:0.1489 D_Loss:0.0014\n",
            "E[91/100] S[20/25] G_Loss:0.1516 D_Loss:0.0012\n",
            "End of Epoch 91 | Avg. G_Loss: 0.1474 | Avg. D_Loss: 0.0014\n",
            "PSNR on sample image: 23.4973 dB\n",
            "E[92/100] S[10/25] G_Loss:0.1386 D_Loss:0.0015\n",
            "E[92/100] S[20/25] G_Loss:0.1443 D_Loss:0.0011\n",
            "End of Epoch 92 | Avg. G_Loss: 0.1454 | Avg. D_Loss: 0.0013\n",
            "PSNR on sample image: 24.8633 dB\n",
            "E[93/100] S[10/25] G_Loss:0.1483 D_Loss:0.0013\n",
            "E[93/100] S[20/25] G_Loss:0.1317 D_Loss:0.0017\n",
            "End of Epoch 93 | Avg. G_Loss: 0.1445 | Avg. D_Loss: 0.0013\n",
            "PSNR on sample image: 24.6432 dB\n",
            "E[94/100] S[10/25] G_Loss:0.1419 D_Loss:0.0014\n",
            "E[94/100] S[20/25] G_Loss:0.1500 D_Loss:0.0012\n",
            "End of Epoch 94 | Avg. G_Loss: 0.1440 | Avg. D_Loss: 0.0012\n",
            "PSNR on sample image: 21.8868 dB\n",
            "E[95/100] S[10/25] G_Loss:0.1480 D_Loss:0.0012\n",
            "E[95/100] S[20/25] G_Loss:0.1322 D_Loss:0.0015\n",
            "End of Epoch 95 | Avg. G_Loss: 0.1430 | Avg. D_Loss: 0.0013\n",
            "PSNR on sample image: 23.7506 dB\n",
            "E[96/100] S[10/25] G_Loss:0.1243 D_Loss:0.0013\n",
            "E[96/100] S[20/25] G_Loss:0.1419 D_Loss:0.0011\n",
            "End of Epoch 96 | Avg. G_Loss: 0.1428 | Avg. D_Loss: 0.0012\n",
            "PSNR on sample image: 22.8297 dB\n",
            "E[97/100] S[10/25] G_Loss:0.1434 D_Loss:0.0013\n",
            "E[97/100] S[20/25] G_Loss:0.1444 D_Loss:0.0013\n",
            "End of Epoch 97 | Avg. G_Loss: 0.1413 | Avg. D_Loss: 0.0013\n",
            "PSNR on sample image: 22.9869 dB\n",
            "E[98/100] S[10/25] G_Loss:0.1359 D_Loss:0.0012\n",
            "E[98/100] S[20/25] G_Loss:0.1326 D_Loss:0.0019\n",
            "End of Epoch 98 | Avg. G_Loss: 0.1405 | Avg. D_Loss: 0.0016\n",
            "PSNR on sample image: 21.6775 dB\n",
            "E[99/100] S[10/25] G_Loss:0.1392 D_Loss:0.0014\n",
            "E[99/100] S[20/25] G_Loss:0.1429 D_Loss:0.0015\n",
            "End of Epoch 99 | Avg. G_Loss: 0.1396 | Avg. D_Loss: 0.0016\n",
            "PSNR on sample image: 24.0311 dB\n",
            "E[100/100] S[10/25] G_Loss:0.1264 D_Loss:0.0018\n",
            "E[100/100] S[20/25] G_Loss:0.1445 D_Loss:0.0015\n",
            "End of Epoch 100 | Avg. G_Loss: 0.1392 | Avg. D_Loss: 0.0017\n",
            "PSNR on sample image: 25.3244 dB\n",
            "✅ Saving checkpoint for epoch 100...\n",
            "🏁 Finished Training!\n"
          ]
        }
      ]
    }
  ]
}